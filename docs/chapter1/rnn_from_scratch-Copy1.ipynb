{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bbc26a7-be2e-45d6-96c0-e50edd84e5f0",
   "metadata": {},
   "source": [
    "# RNN 简介\n",
    "\n",
    "# 时间序列模型概念简介\n",
    "循环神经网络（RNN）是一种神经网络类型，其神经元的输出在下一个时间步会反馈作为输入，使网络具有处理序列数据的能力。它能处理变长序列，挖掘数据中的时序信息，不过存在长期依赖问题，即难以处理长序列中相距较远的信息关联。\n",
    "RNN与普通神经网络的主要区别在于其具有记忆功能，神经元的输出能作为下一步输入，可处理序列数据，且输入和输出长度不固定；普通神经网络一般处理独立同分布的数据，层与层之间是简单的前馈连接关系，输入输出的长度通常是固定的。\n",
    "\n",
    "RNN的应用场景广泛，在自然语言处理方面，可用于语言模型来预测下一个单词的概率，还能完成机器翻译、文本生成任务；在语音识别领域，能够处理语音这种时间序列信号，提高识别准确率；在时间序列预测中，像股票价格预测、天气预测等，RNN通过学习历史数据模式预测未来值；在视频分析中，它可以处理视频帧序列，进行动作识别等操作。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RNN网络结构图\n",
    "![图1](images/rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed32eb-d5dc-4fe6-9164-3d621a98d2fa",
   "metadata": {},
   "source": [
    "RNN公式：\n",
    "$$\n",
    "[\n",
    "\\boldsymbol{h}_t = tanh(\\boldsymbol{h}_{t-1} \\boldsymbol{W}_h + \\boldsymbol{x}_t \\boldsymbol{W}_x + \\boldsymbol{b})\n",
    "]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3672e561-69a7-416d-93f3-39c6bb131577",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51511bf4-3182-4f3d-8482-5f36d3ab755b",
   "metadata": {},
   "source": [
    "# 观察torch.nn.RNN的输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e152dd0d-8abf-46d3-85d4-f418335ad2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98eb8147-8728-49ac-b7ec-bbd4c85e27bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2211,  0.0713, -0.7325,  0.2592]]])\n",
      "tensor([[[-0.4568, -0.2468,  0.2100]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 1, 3])\n",
      "tensor([[[-0.4568, -0.2468,  0.2100]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 单向、单层rnn\n",
    "# 1个时间步\n",
    "# batch_first=True表示输入数据的维度为[batch_size, seq_len, input_dim], input_dim在后文也称为input_size\n",
    "single_rnn = nn.RNN(input_size=4, hidden_size=3, num_layers=1, batch_first=True) \n",
    "input = torch.randn(1, 1, 4) # 输入数据维度为[batch_size, time_steps_num, input_dim]\n",
    "output, h_n = single_rnn(input) # output维度为[batch_size, time_steps_num, hidden_size=3]，h_n维度为[num_layers=1, batch_size, hidden_size=3]\n",
    "print(input,output, output.shape, h_n, h_n.shape,  sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92793422-5d08-49fd-bad4-7a18a428c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3055,  0.0048, -0.0629,  0.4583],\n",
      "         [ 0.8229,  1.5621,  0.1653,  0.5145]]])\n",
      "tensor([[[-0.2296, -0.4769, -0.0592],\n",
      "         [ 0.0134, -0.5053, -0.6914]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 2, 3])\n",
      "tensor([[[ 0.0134, -0.5053, -0.6914]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 单向、单层rnn\n",
    "# 2个时间步\n",
    "single_rnn = nn.RNN(input_size=4, hidden_size=3, num_layers=1, batch_first=True) # 输入数据的维度为[batch_size, time_steps_num, input_dim]\n",
    "input = torch.randn(1, 2, 4) # 输入数据维度为[batch_size, time_steps_num, input_dim]\n",
    "output, h_n = single_rnn(input) # output维度为[batch_size, time_steps_num, hidden_size=3]，h_n维度为[num_layers=1, batch_size, hidden_size=3]\n",
    "print(input,output, output.shape, h_n, h_n.shape,  sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40a4c3-8063-4b5c-8892-d0dce778f265",
   "metadata": {},
   "source": [
    "output输出为不同时间步的隐状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06c81d55-80f1-496e-8c00-57db4bf6edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0293, -0.2261,  0.3965, -0.8093,  0.5495, -0.2421],\n",
      "         [ 0.3172, -0.4707, -0.0548, -0.9589,  0.5515,  0.0759],\n",
      "         [-0.3819, -0.9026,  0.2700, -0.6062,  0.9286, -0.6791],\n",
      "         [-0.9650,  0.2898,  0.9175, -0.9964,  0.3749, -0.4732],\n",
      "         [ 0.4947, -0.6497,  0.0801, -0.3799,  0.8914, -0.4917]],\n",
      "\n",
      "        [[ 0.1236,  0.6172,  0.5129, -0.9334, -0.7831,  0.1077],\n",
      "         [ 0.7416,  0.5501,  0.4543, -0.8432, -0.2094, -0.3928],\n",
      "         [ 0.9069, -0.6283, -0.4312, -0.5202,  0.6983, -0.2993],\n",
      "         [ 0.2843, -0.9798, -0.5583, -0.0776,  0.9733,  0.1556],\n",
      "         [-0.9714, -0.1158,  0.7961, -0.9926,  0.1743,  0.1932]],\n",
      "\n",
      "        [[ 0.8565, -0.8896, -0.7905, -0.4024,  0.6848,  0.4695],\n",
      "         [-0.2559,  0.0835,  0.7091, -0.7468, -0.3244, -0.6832],\n",
      "         [-0.3923, -0.4974,  0.4001, -0.9646,  0.8942,  0.0540],\n",
      "         [ 0.2724, -0.8785, -0.4926, -0.8918,  0.8703,  0.0652],\n",
      "         [ 0.4889, -0.8752, -0.3374,  0.1035,  0.6077, -0.4534]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "torch.Size([3, 5, 6])\n",
      "tensor([[[ 0.4947, -0.6497,  0.0801],\n",
      "         [-0.9714, -0.1158,  0.7961],\n",
      "         [ 0.4889, -0.8752, -0.3374]],\n",
      "\n",
      "        [[-0.8093,  0.5495, -0.2421],\n",
      "         [-0.9334, -0.7831,  0.1077],\n",
      "         [-0.4024,  0.6848,  0.4695]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 双向、单层rnn\n",
    "bi_rnn = nn.RNN(input_size=4, hidden_size=3, num_layers=1, batch_first=True, bidirectional=True)\n",
    "bi_output, bi_h_n = bi_rnn(input)\n",
    "print(bi_output, bi_output.shape, bi_h_n, bi_h_n.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0b04f-d59f-421a-b5b8-6d8f87b8d06e",
   "metadata": {},
   "source": [
    "# 从零手搓 RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943a164-b997-4947-bce8-8618b421ef3d",
   "metadata": {},
   "source": [
    "### 自定义单向单层RNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b52299c8-f30e-4f86-8f39-c1a35116dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46bc4c-6957-49af-bad3-42163c342945",
   "metadata": {},
   "source": [
    "对照RNN公式实现RNN Layer\n",
    "$$\n",
    "[\n",
    "\\boldsymbol{h}_t = tanh(\\boldsymbol{h}_{t-1} \\boldsymbol{W}_h + \\boldsymbol{x}_t \\boldsymbol{W}_x + \\boldsymbol{b})\n",
    "]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a73914e1-9e0f-4296-82f9-9397b2655353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLayer(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers=1, batch_first=True):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.bidirectional = False\n",
    "        super().__init__()\n",
    "        self.W_ih = nn.Parameter(torch.rand(self.input_size, self.hidden_size))\n",
    "        self.W_hh = nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.b_ih = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "        self.b_hh = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "        \n",
    "    def forward(self,x_t,h_prev=None):\n",
    "        # part 1: torch.matmul(x_t, self.W_ih)\n",
    "        # x_t包含多个时间步，形状为[batch_size, time_steps_num, input_dim]\n",
    "        # W_ih形状为[input_dim, hidden_size]\n",
    "        # torch.matmul(x_t, self.W_ih) 输出矩阵形状为[batch_size, time_steps_num, hidden_size]\n",
    "        # part 2: torch.matmul(h_prev, self.W_hh)\n",
    "        # h_prev 形状为[batch_size, time_steps_num, hidden_size]\n",
    "        # W_hh形状为[hidden_size, hidden_size]\n",
    "        # torch.matmul(h_prev, self.W_hh) 输出矩阵形状为[batch_size, time_steps_num, hidden_size]\n",
    "        if h_prev == None:\n",
    "             h_prev = torch.zeros( x_t.size(0), self.hidden_size)\n",
    "        output = torch.tanh(torch.matmul(x_t, self.W_ih) + self.b_ih + torch.matmul(h_prev, self.W_hh) + self.b_hh)\n",
    "        return output,output[:,-1,:].unsqueeze(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9415e-d1c4-452d-8424-2f11f0d789f4",
   "metadata": {},
   "source": [
    "### 测试输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c66b3a31-7bee-4b8d-a72e-d21a8e2b886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5654, -0.4903, -0.5631],\n",
      "         [-0.9804, -0.9930, -0.9965],\n",
      "         [-0.6663, -0.3654, -0.2664],\n",
      "         [ 0.3566, -0.1782,  0.1626],\n",
      "         [-0.3247, -0.6990, -0.6349]]], grad_fn=<TanhBackward0>)\n",
      "torch.Size([1, 5, 3])\n",
      "tensor([[[-0.3247, -0.6990, -0.6349]]], grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 单向、单层rnn\n",
    "single_rnn = RNNLayer(input_size=4, hidden_size=3, num_layers=1, batch_first=True) # batch_first=True表示输入数据的维度为[batch_size, time_steps_num, input_dim]\n",
    "input = torch.randn(1, 5, 4) # 输入数据维度为[batch_size, time_steps_num, input_size]\n",
    "output,h_n = single_rnn(input) # output维度为[batch_size, time_steps_num, hidden_size=3]，h_n维度为[num_layers=1, batch_size, hidden_size=3]\n",
    "print(output, output.shape, h_n, h_n.shape,  sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c2d2b-27bc-4e06-8c55-39cfdf95a6c9",
   "metadata": {},
   "source": [
    "输出结果形状与nn.RNN一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191a8f4-53f7-4c0b-b6c4-a1f95f54e0cd",
   "metadata": {},
   "source": [
    "### 用nn.RNN建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30c62d15-3524-4d4b-b063-d65a183e680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3683f244-bd97-4dc4-af97-a94d86342448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b7047-3074-45ea-8221-0ea3684fb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.one_hot.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ee0112ac-52fc-4d40-b946-2c2bcf193e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = output_size# 输入是One hot, output_size和vocab_size 都是词表大小\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 这里的X输入为word index\n",
    "        X = F.one_hot(torch.tensor(torch.tensor(X)),self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        print(X.size())\n",
    "        state_0 = torch.zeros(self.num_layers, X.size(0), self.hidden_size).to(X.device) # 隐状态的形状为[层数，batch_size,hidden_size]\n",
    "        out, state = self.rnn(X, state_0) \n",
    "        out = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e830872d-e4ea-4a74-ac28-92d1b7f96448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor([1,2]),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "02a419cf-f1c3-4b16-8767-ba80ce3a0c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "one_hot(tensor, num_classes=-1) -> LongTensor\n",
      "\n",
      "Takes LongTensor with index values of shape ``(*)`` and returns a tensor\n",
      "of shape ``(*, num_classes)`` that have zeros everywhere except where the\n",
      "index of last dimension matches the corresponding value of the input tensor,\n",
      "in which case it will be 1.\n",
      "\n",
      "See also `One-hot on Wikipedia`_ .\n",
      "\n",
      ".. _One-hot on Wikipedia:\n",
      "    https://en.wikipedia.org/wiki/One-hot\n",
      "\n",
      "Arguments:\n",
      "    tensor (LongTensor): class values of any shape.\n",
      "    num_classes (int):  Total number of classes. If set to -1, the number\n",
      "        of classes will be inferred as one greater than the largest class\n",
      "        value in the input tensor.\n",
      "\n",
      "Returns:\n",
      "    LongTensor that has one more dimension with 1 values at the\n",
      "    index of last dimension indicated by the input, and 0 everywhere\n",
      "    else.\n",
      "\n",
      "Examples:\n",
      "    >>> F.one_hot(torch.arange(0, 5) % 3)\n",
      "    tensor([[1, 0, 0],\n",
      "            [0, 1, 0],\n",
      "            [0, 0, 1],\n",
      "            [1, 0, 0],\n",
      "            [0, 1, 0]])\n",
      "    >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5)\n",
      "    tensor([[1, 0, 0, 0, 0],\n",
      "            [0, 1, 0, 0, 0],\n",
      "            [0, 0, 1, 0, 0],\n",
      "            [1, 0, 0, 0, 0],\n",
      "            [0, 1, 0, 0, 0]])\n",
      "    >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3)\n",
      "    tensor([[[1, 0, 0],\n",
      "             [0, 1, 0]],\n",
      "            [[0, 0, 1],\n",
      "             [1, 0, 0]],\n",
      "            [[0, 1, 0],\n",
      "             [0, 0, 1]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(F.one_hot.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a29b0-6c9f-479f-8db2-e30085795294",
   "metadata": {},
   "source": [
    "### 测试模型输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1854c51-852d-493a-85ed-bd7ba700be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
    "    \"\"\"在prefix后面生成新字符\n",
    "\n",
    "    Defined in :numref:`sec_rnn_scratch`\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input =  lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f8f2050-c72c-49e2-be36-f8453961f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_time_machine(batch_size, num_steps,\n",
    "                           use_random_iter=False, max_tokens=10000):\n",
    "    \"\"\"返回时光机器数据集的迭代器和词表\n",
    "\n",
    "    Defined in :numref:`sec_language_model`\"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens)\n",
    "    return data_iter, data_iter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbee854-92f1-4b1e-8a4c-47f5f961b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\n",
    "\n",
    "    Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e8864-21de-482b-9156-dfa2626dc8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\n",
    "\n",
    "    Defined in :numref:`sec_language_model`\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = d2l.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = d2l.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8fc5d087-3f44-4283-8be2-412323b229c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        \"\"\"Defined in :numref:`sec_language_model`\"\"\"\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = d2l.seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = d2l.seq_data_iter_sequential\n",
    "        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b917a80e-5a97-46a0-aa44-c91fcd7ebc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'd2l' has no attribute 'load_data_time_machine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size, num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m35\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_iter, vocab \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_time_machine\u001b[49m(batch_size, num_steps)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'd2l' has no attribute 'load_data_time_machine'"
     ]
    }
   ],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5c0a176a-09b2-4ddc-a0c3-3caf18c42e99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m CustomRNN(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m predict_ch8(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime traveller \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m, model, \u001b[43mvocab\u001b[49m, d2l\u001b[38;5;241m.\u001b[39mtry_gpu())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "model = CustomRNN(256, 10,1,256)\n",
    "predict_ch8('time traveller ', 10, model, vocab, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "50dc8609-91b2-4ef6-ab6b-1d896c042148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46949/3184043730.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = F.one_hot(torch.tensor(torch.tensor(X)),self.vocab_size)\n"
     ]
    }
   ],
   "source": [
    "model = CustomRNN(256, 10,1,256)\n",
    "Y = model([[13,12,14]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "598e5158-47e7-4ad0-8053-30fe70d058b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3c5520c5-56e7-490e-b765-95b9b6e75210",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Y.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6a2cfa8b-b426-4716-8801-3a616d6214af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'动'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1b6ad78c-9daa-4cf0-8be8-e7178601b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(init_chars,model,time_steps_num,idx_to_char,char_to_idx):\n",
    "    X = []\n",
    "    for c in init_chars:\n",
    "        X.append(char_to_idx[c])\n",
    "    output = init_chars\n",
    "    print(X)\n",
    "    for i in range(time_steps_num):\n",
    "        Y= model([X])\n",
    "        idx = Y.argmax(dim=1)\n",
    "        X.append(idx)\n",
    "        output+=idx_to_char[idx]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807171f-dcb5-4e5c-aa3e-d7b3bff6b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2fce464f-6765-42f3-bb2f-8e629beb3486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\n",
      "torch.Size([1, 1, 256])\n",
      "torch.Size([1, 2, 256])\n",
      "torch.Size([1, 3, 256])\n",
      "torch.Size([1, 4, 256])\n",
      "torch.Size([1, 5, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46949/3184043730.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = F.one_hot(torch.tensor(torch.tensor(X)),self.vocab_size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'构3将连将连'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('构', model,5,idx_to_char,char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3f88a14-5d14-4bcd-b790-461ea0e293f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.rnn = RNNLayer(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X, h_prev):\n",
    "        \n",
    "        print(x.size())\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        hiddens = []\n",
    "        for t in range(seq_length):\n",
    "            x_t = x[:, t, :]\n",
    "            h_t = torch.tanh(torch.mm(x_t, self.W_ih) + self.b_ih + torch.mm(h_prev, self.W_hh) + self.b_hh)\n",
    "            hiddens.append(h_t)\n",
    "            h_prev = h_t\n",
    "        h_final = hiddens[-1]\n",
    "        output = self.fc(h_final)\n",
    "        return output, h_prev\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed47337d-d10a-4bd5-95a2-fc8a7d52d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNNLayer(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "num_hiddens = 256\n",
    "# rnn_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens) # 已测试\n",
    "rnn_layer = RNNLayer(input_size=vocab_size, hidden_size=num_hiddens)\n",
    "num_hiddens = 256\n",
    "# rnn_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens) # 已测试\n",
    "rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)\n",
    "# 本类已保存在d2lzh_pytorch包中方便以后使用\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, rnn_layer, vocab_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = rnn_layer\n",
    "        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \n",
    "        self.vocab_size = vocab_size\n",
    "        self.dense = nn.Linear(self.hidden_size, vocab_size)\n",
    "        self.state = None\n",
    "\n",
    "    def forward(self, inputs, state): # inputs: (batch, seq_len)\n",
    "        # 获取one-hot向量表示\n",
    "        X = nn.functional.one_hot(inputs, self.vocab_size) # X是个list\n",
    "        Y, self.state = self.rnn(X, state)\n",
    "        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\n",
    "        # 形状为(num_steps * batch_size, vocab_size)\n",
    "        output = self.dense(Y.view(-1, Y.shape[-1]))\n",
    "        return output, self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90b879-7712-44b4-b15a-111c0473c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.functional.one_hot.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "168e797f-a275-45d5-8481-55d1c306d851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 0],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 6).view(3,2) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f8b165d6-da2f-4442-a5b1-83b211a69bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_lyrics():\n",
    "    #with zipfile.ZipFile('./test.txt') as zin:\n",
    "    with open('test.txt') as f:\n",
    "            corpus_chars = f.read()#.decode('utf-8')\n",
    "    # corpus_chars[:40]  # '想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每'\n",
    "\n",
    "    # 将换行符替换成空格；仅使用前1万个字符来训练模型\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "\n",
    "    # 将每个字符映射成索引\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)  # 1027\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    sample = corpus_indices[:20]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "87ecffdd-81e8-4adb-a635-30b9aeb61a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = load_data_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "40845776-dc7f-4755-8375-2b09daeab446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 'n', '节', 'A', '”']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6a284b83-6f39-4076-9de0-7c33be34e28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R': 0,\n",
       " 'n': 1,\n",
       " '节': 2,\n",
       " 'A': 3,\n",
       " '”': 4,\n",
       " '协': 5,\n",
       " '态': 6,\n",
       " '征': 7,\n",
       " '自': 8,\n",
       " 'y': 9,\n",
       " '访': 10,\n",
       " '队': 11,\n",
       " '构': 12,\n",
       " '应': 13,\n",
       " '解': 14,\n",
       " '言': 15,\n",
       " '批': 16,\n",
       " '次': 17,\n",
       " '持': 18,\n",
       " '做': 19,\n",
       " '另': 20,\n",
       " '题': 21,\n",
       " '概': 22,\n",
       " '正': 23,\n",
       " '回': 24,\n",
       " '无': 25,\n",
       " '度': 26,\n",
       " '能': 27,\n",
       " '将': 28,\n",
       " '和': 29,\n",
       " '共': 30,\n",
       " '远': 31,\n",
       " '/': 32,\n",
       " '问': 33,\n",
       " '需': 34,\n",
       " '开': 35,\n",
       " 'P': 36,\n",
       " '处': 37,\n",
       " '息': 38,\n",
       " '符': 39,\n",
       " '列': 40,\n",
       " '不': 41,\n",
       " '3': 42,\n",
       " '按': 43,\n",
       " 'p': 44,\n",
       " '件': 45,\n",
       " '含': 46,\n",
       " '术': 47,\n",
       " '是': 48,\n",
       " '.': 49,\n",
       " '方': 50,\n",
       " '缺': 51,\n",
       " '中': 52,\n",
       " '链': 53,\n",
       " '何': 54,\n",
       " '式': 55,\n",
       " '风': 56,\n",
       " 't': 57,\n",
       " '码': 58,\n",
       " '量': 59,\n",
       " '仅': 60,\n",
       " 'J': 61,\n",
       " '递': 62,\n",
       " 'h': 63,\n",
       " '增': 64,\n",
       " '知': 65,\n",
       " '刚': 66,\n",
       " '间': 67,\n",
       " '享': 68,\n",
       " '具': 69,\n",
       " '面': 70,\n",
       " '为': 71,\n",
       " '客': 72,\n",
       " '调': 73,\n",
       " '思': 74,\n",
       " '反': 75,\n",
       " '压': 76,\n",
       " '视': 77,\n",
       " '明': 78,\n",
       " '移': 79,\n",
       " 'W': 80,\n",
       " '型': 81,\n",
       " '务': 82,\n",
       " '跳': 83,\n",
       " '成': 84,\n",
       " '足': 85,\n",
       " '性': 86,\n",
       " '计': 87,\n",
       " '够': 88,\n",
       " '公': 89,\n",
       " '操': 90,\n",
       " '念': 91,\n",
       " '）': 92,\n",
       " '始': 93,\n",
       " '直': 94,\n",
       " '行': 95,\n",
       " '子': 96,\n",
       " '体': 97,\n",
       " '名': 98,\n",
       " '缓': 99,\n",
       " '标': 100,\n",
       " 'I': 101,\n",
       " '利': 102,\n",
       " '全': 103,\n",
       " '特': 104,\n",
       " '到': 105,\n",
       " '发': 106,\n",
       " 'a': 107,\n",
       " 'L': 108,\n",
       " '映': 109,\n",
       " '没': 110,\n",
       " '使': 111,\n",
       " '生': 112,\n",
       " '空': 113,\n",
       " 'f': 114,\n",
       " '理': 115,\n",
       " '媒': 116,\n",
       " '于': 117,\n",
       " '1': 118,\n",
       " '转': 119,\n",
       " '争': 120,\n",
       " '示': 121,\n",
       " 'e': 122,\n",
       " '议': 123,\n",
       " '同': 124,\n",
       " '答': 125,\n",
       " '一': 126,\n",
       " '据': 127,\n",
       " '部': 128,\n",
       " '每': 129,\n",
       " 'T': 130,\n",
       " '改': 131,\n",
       " '套': 132,\n",
       " '决': 133,\n",
       " '传': 134,\n",
       " '象': 135,\n",
       " '作': 136,\n",
       " '真': 137,\n",
       " '制': 138,\n",
       " '楚': 139,\n",
       " '管': 140,\n",
       " '最': 141,\n",
       " '通': 142,\n",
       " '述': 143,\n",
       " '般': 144,\n",
       " '杂': 145,\n",
       " '信': 146,\n",
       " '简': 147,\n",
       " 's': 148,\n",
       " '设': 149,\n",
       " '动': 150,\n",
       " '删': 151,\n",
       " '数': 152,\n",
       " '如': 153,\n",
       " '只': 154,\n",
       " '地': 155,\n",
       " '：': 156,\n",
       " '要': 157,\n",
       " '消': 158,\n",
       " '软': 159,\n",
       " '率': 160,\n",
       " '路': 161,\n",
       " 'C': 162,\n",
       " 'l': 163,\n",
       " '请': 164,\n",
       " '求': 165,\n",
       " '原': 166,\n",
       " '点': 167,\n",
       " '靠': 168,\n",
       " '某': 169,\n",
       " '格': 170,\n",
       " '对': 171,\n",
       " '（': 172,\n",
       " '等': 173,\n",
       " '师': 174,\n",
       " '包': 175,\n",
       " '存': 176,\n",
       " 'H': 177,\n",
       " '块': 178,\n",
       " 'g': 179,\n",
       " '进': 180,\n",
       " '入': 181,\n",
       " '辑': 182,\n",
       " 'M': 183,\n",
       " '器': 184,\n",
       " '架': 185,\n",
       " 'U': 186,\n",
       " '输': 187,\n",
       " '口': 188,\n",
       " '超': 189,\n",
       " '描': 190,\n",
       " '抽': 191,\n",
       " '种': 192,\n",
       " '必': 193,\n",
       " 'o': 194,\n",
       " '字': 195,\n",
       " '级': 196,\n",
       " '熟': 197,\n",
       " '绑': 198,\n",
       " 'G': 199,\n",
       " '内': 200,\n",
       " '本': 201,\n",
       " '三': 202,\n",
       " '表': 203,\n",
       " '0': 204,\n",
       " '境': 205,\n",
       " '送': 206,\n",
       " 'i': 207,\n",
       " '户': 208,\n",
       " '步': 209,\n",
       " '服': 210,\n",
       " '界': 211,\n",
       " '有': 212,\n",
       " 'c': 213,\n",
       " '力': 214,\n",
       " '与': 215,\n",
       " '多': 216,\n",
       " '缩': 217,\n",
       " '-': 218,\n",
       " '或': 219,\n",
       " '机': 220,\n",
       " 'u': 221,\n",
       " '序': 222,\n",
       " '事': 223,\n",
       " '适': 224,\n",
       " '层': 225,\n",
       " '角': 226,\n",
       " '模': 227,\n",
       " '用': 228,\n",
       " '引': 229,\n",
       " '驱': 230,\n",
       " '“': 231,\n",
       " '连': 232,\n",
       " '文': 233,\n",
       " '执': 234,\n",
       " '形': 235,\n",
       " 'd': 236,\n",
       " '透': 237,\n",
       " '端': 238,\n",
       " '源': 239,\n",
       " '分': 240,\n",
       " '的': 241,\n",
       " '所': 242,\n",
       " '法': 243,\n",
       " '流': 244,\n",
       " '支': 245,\n",
       " '展': 246,\n",
       " '个': 247,\n",
       " '合': 248,\n",
       " 'S': 249,\n",
       " '离': 250,\n",
       " '注': 251,\n",
       " '逻': 252,\n",
       " 'D': 253,\n",
       " '号': 254,\n",
       " '高': 255,\n",
       " 'b': 256,\n",
       " '后': 257,\n",
       " '终': 258,\n",
       " '场': 259,\n",
       " '2': 260,\n",
       " '续': 261,\n",
       " 'r': 262,\n",
       " '基': 263,\n",
       " '射': 264,\n",
       " '储': 265,\n",
       " '可': 266,\n",
       " '景': 267,\n",
       " 'O': 268,\n",
       " '资': 269,\n",
       " '二': 270,\n",
       " '义': 271,\n",
       " '控': 272,\n",
       " '较': 273,\n",
       " '乏': 274,\n",
       " '否': 275,\n",
       " '从': 276,\n",
       " '，': 277,\n",
       " '上': 278,\n",
       " '化': 279,\n",
       " '第': 280,\n",
       " '语': 281,\n",
       " 'N': 282,\n",
       " '系': 283,\n",
       " 'm': 284,\n",
       " '在': 285,\n",
       " '运': 286,\n",
       " '道': 287,\n",
       " '程': 288,\n",
       " '过': 289,\n",
       " '统': 290,\n",
       " '效': 291,\n",
       " '状': 292,\n",
       " '复': 293,\n",
       " '想': 294,\n",
       " '业': 295,\n",
       " '接': 296,\n",
       " '代': 297,\n",
       " '少': 298,\n",
       " '两': 299,\n",
       " '下': 300,\n",
       " '目': 301,\n",
       " '向': 302,\n",
       " '把': 303,\n",
       " '关': 304,\n",
       " '、': 305,\n",
       " '编': 306,\n",
       " '清': 307,\n",
       " '之': 308,\n",
       " ' ': 309,\n",
       " '完': 310,\n",
       " '4': 311,\n",
       " '才': 312,\n",
       " '定': 313,\n",
       " 'E': 314}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9e086bd-5fc2-406c-9447-458af53603ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(X, n_class):  \n",
    "    # X shape: (batch, seqd_len), output: seq_len elements of (batch, n_class)\n",
    "    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "546887fc-623d-4623-b271-a77b6bf0abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n",
    "                      char_to_idx):\n",
    "    state = None\n",
    "    output = [char_to_idx[prefix[0]]] # output会记录prefix加上输出\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = torch.tensor([output[-1]], device=device).view(1, 1)\n",
    "        if state is not None:\n",
    "            if isinstance(state, tuple): # LSTM, state:(h, c)  \n",
    "                state = (state[0].to(device), state[1].to(device))\n",
    "            else:   \n",
    "                state = state.to(device)\n",
    "            \n",
    "        (Y, state) = model(X, state)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e495209-a365-4bfa-a36d-96d0a30f7fef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m RNNModel(rnn_layer, vocab_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpredict_rnn_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m分开\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_to_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_to_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[77], line 14\u001b[0m, in \u001b[0;36mpredict_rnn_pytorch\u001b[0;34m(prefix, num_chars, model, vocab_size, device, idx_to_char, char_to_idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[1;32m     12\u001b[0m         state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m (Y, state) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(prefix) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     16\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(char_to_idx[prefix[t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch-2.0.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[65], line 21\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, state): \u001b[38;5;66;03m# inputs: (batch, seq_len)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# 获取one-hot向量表示\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     X \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size) \u001b[38;5;66;03m# X是个list\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     Y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# 形状为(num_steps * batch_size, vocab_size)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(Y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch-2.0.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch-2.0.0/lib/python3.9/site-packages/torch/nn/modules/rnn.py:509\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_tanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    513\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    514\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m    515\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "device='cuda:0'\n",
    "model = RNNModel(rnn_layer, vocab_size).to(device)\n",
    "predict_rnn_pytorch('分开', 10, model, vocab_size, device, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c5864-7dc1-4c9d-ac3f-91dbfa93aebb",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "### 数据预处理\n",
    "- 读取数据集：\n",
    "  首先需要获取周杰伦的歌词数据集，可以从网络上搜索整理其歌词文本，将所有歌词保存到一个文本文件中，如jaychou_lyrics.txt。使用 Python 的open()函数读取文件内容，并进行必要的字符编码转换 。\n",
    "- 建立字符索引：\n",
    "将歌词中的每个字符映射为一个从 0 开始的连续整数索引，构建字符到索引的字典char_to_idx以及索引到字符的字典idx_to_char。通过遍历歌词文本，找出所有不同的字符，然后为每个字符分配一个唯一的索引。同时，可以得到词典大小vocab_size，即不同字符的数量 。\n",
    "- 数据采样:\n",
    "\n",
    "  对处理后的数据进行采样，以便生成训练所需的小批量数据。常见的采样方式有随机采样和相邻采样两种 ：\n",
    "- 随机采样：\n",
    "  每次从数据中随机选择一定长度的连续字符序列作为一个样本，同时对应的下一个字符作为该样本的标签。例如，若设定时间步数为num_steps，则每次随机选取num_steps个连续字符作为输入样本，其后面的一个字符作为输出标签。\n",
    "相邻采样：按照顺序依次选取连续的字符序列作为样本和标签，即第i个样本的输入是从i到i + num_steps - 1的字符序列，其标签则是从i + 1到i + num_steps的字符序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a97bd370-f7ce-40ce-a1b9-81581e393ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 6\u001b[0m rnn \u001b[38;5;241m=\u001b[39m \u001b[43mCustomRNN\u001b[49m(input_size, hidden_size, num_layers, output_size)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 模拟输入数据（实际要根据歌词进行词向量等转换），这里假设一批次2条数据，序列长度5，维度为input_size\u001b[39;00m\n\u001b[1;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, input_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomRNN' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 假设输入歌词维度、隐藏层维度、层数、输出维度等\n",
    "input_size = 100\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "output_size = 100\n",
    "rnn = CustomRNN(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# 模拟输入数据（实际要根据歌词进行词向量等转换），这里假设一批次2条数据，序列长度5，维度为input_size\n",
    "x = torch.randn(2, 5, input_size)\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    h_prev = rnn.init_hidden(2)\n",
    "    output, h_prev = rnn(x, h_prev)\n",
    "    loss = criterion(output, torch.randn(2, output_size))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda97458-2dfc-465e-86ec-92488878923c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254eb864-0cc4-4bde-9697-0825c8973534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dd3fbe-6bfe-41a1-8f2c-bd332d430b09",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "参数初始化：初始化模型的参数，如词嵌入维度embedding_dim、隐藏层维度hidden_dim等，并定义损失函数和优化器。例如，可以使用交叉熵损失函数nn.CrossEntropyLoss()和随机梯度下降优化器torch.optim.SGD() 。\n",
    "训练循环：在训练循环中，按照设定的批次大小和采样方式获取训练数据，将数据输入到模型中进行前向传播，计算损失值，然后使用优化器进行反向传播更新模型参数。在每个训练周期，可以打印出当前的损失值，以观察模型的训练进度 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1929d48b-43d2-48fb-b9a0-db6967fd8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = None\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_y in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output, hidden = model(batch_x, hidden)\n",
    "            loss = criterion(output, batch_y.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            hidden = hidden.detach()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(data_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec35fc7-096d-4289-ae80-8ffefa1568cf",
   "metadata": {},
   "source": [
    "### 模型测试与效果评估\n",
    "- 生成歌词：训练完成后，可以使用训练好的模型来生成周杰伦风格的歌词。给定一个起始字符或字符序列，通过模型预测下一个可能的字符，然后将预测的字符作为新的输入，继续预测下一个字符，以此类推，生成一段歌词 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ec35fb-0b34-47e5-8bc7-0c3b88eddfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, char_to_idx, idx_to_char, start_text, length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_text = torch.tensor([char_to_idx[char] for char in start_text]).unsqueeze(0)\n",
    "        hidden = None\n",
    "        generated_text = start_text\n",
    "        for _ in range(length):\n",
    "            output, hidden = model(input_text, hidden)\n",
    "            output_probs = torch.softmax(output, dim=1)\n",
    "            top_prob, top_idx = torch.topk(output_probs, k=1)\n",
    "            top_char = idx_to_char[top_idx.item()]\n",
    "            generated_text += top_char\n",
    "            input_text = torch.tensor([top_idx]).unsqueeze(0)\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2de9b-b4b6-4a16-bd29-09dcec41cfa1",
   "metadata": {},
   "source": [
    "- 效果评估：可以从多个角度评估生成歌词的效果，如歌词的通顺性、连贯性、是否符合周杰伦的风格等。一种简单的方法是人工观察和评价生成的歌词，判断其是否具有一定的合理性和艺术感。也可以使用一些自动评估指标，如困惑度（Perplexity）等来定量地评估模型的性能，但困惑度指标并非完全能够准确反映生成文本的质量，仅供参考."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8ca7fb-7be8-44e7-ae72-6d1c7393a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in data_loader:\n",
    "            output, _ = model(batch_x, None)\n",
    "            loss = criterion(output, batch_y.view(-1))\n",
    "            total_loss += loss.item() * batch_y.numel()\n",
    "            total_count += batch_y.numel()\n",
    "    return torch.exp(torch.tensor(total_loss / total_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876c42-584f-46b2-89a6-279b98a06663",
   "metadata": {},
   "source": [
    "通过以上步骤，就可以利用周杰伦的歌词训练 PyTorch RNN 模型，并对生成歌词的效果进行测试和评估 。需要注意的是，由于歌词的生成具有一定的主观性和创造性，模型的表现可能会因多种因素而有所不同，可通过调整模型结构、参数、训练数据等方式来进一步优化模型的性能 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad6d54-1307-44be-8bd5-e7f8f699e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.0",
   "language": "python",
   "name": "pytorch-2.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
