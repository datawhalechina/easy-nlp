{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bbc26a7-be2e-45d6-96c0-e50edd84e5f0",
   "metadata": {},
   "source": [
    "# RNN 简介\n",
    "\n",
    "# 时间序列模型概念简介\n",
    "简介时序模型的不同之处\n",
    "\n",
    "# RNN网络结构图\n",
    "![rnn](images/rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed32eb-d5dc-4fe6-9164-3d621a98d2fa",
   "metadata": {},
   "source": [
    "RNN公式：\n",
    "![rnn_rule](images/rnn_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51511bf4-3182-4f3d-8482-5f36d3ab755b",
   "metadata": {},
   "source": [
    "# 观察torch.nn.RNN的输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e152dd0d-8abf-46d3-85d4-f418335ad2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98eb8147-8728-49ac-b7ec-bbd4c85e27bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1926, -0.5641, -0.1246],\n",
      "         [ 0.3857, -0.5942,  0.3756],\n",
      "         [-0.7565, -0.9860, -0.6089],\n",
      "         [ 0.1879, -0.8991, -0.3685],\n",
      "         [ 0.4113, -0.8877, -0.5903]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 5, 3])\n",
      "tensor([[[ 0.4113, -0.8877, -0.5903]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 单向、单层rnn\n",
    "single_rnn = nn.RNN(input_size=4, hidden_size=3, num_layers=1, batch_first=True) # batch_first=True表示输入数据的维度为[batch_size, seq_len, input_size]\n",
    "input = torch.randn(1, 5, 4) # 输入数据维度为[batch_size, seq_len, input_size]\n",
    "output, h_n = single_rnn(input) # output维度为[batch_size, seq_len, hidden_size=3]，h_n维度为[num_layers=1, batch_size, hidden_size=3]\n",
    "print(output, output.shape, h_n, h_n.shape,  sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fdc7e1b-e015-4be3-8047-567c8c42f78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7565, -0.9860, -0.6089]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:, 2, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c81d55-80f1-496e-8c00-57db4bf6edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9352, -0.1535,  0.3298,  0.8335, -0.9024, -0.6281],\n",
      "         [ 0.3034, -0.5223, -0.9183,  0.8817, -0.4630, -0.6553],\n",
      "         [ 0.9745, -0.4444,  0.7889,  0.9376, -0.6616, -0.8148],\n",
      "         [ 0.7716, -0.2623, -0.8482,  0.7856, -0.1788, -0.9494],\n",
      "         [ 0.7237, -0.5549, -0.1000,  0.7960, -0.4034, -0.1305]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "torch.Size([1, 5, 6])\n",
      "tensor([[[ 0.7237, -0.5549, -0.1000]],\n",
      "\n",
      "        [[ 0.8335, -0.9024, -0.6281]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 双向、单层rnn\n",
    "bi_rnn = nn.RNN(input_size=4, hidden_size=3, num_layers=1, batch_first=True, bidirectional=True)\n",
    "bi_output, bi_h_n = bi_rnn(input)\n",
    "print(bi_output, bi_output.shape, bi_h_n, bi_h_n.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0b04f-d59f-421a-b5b8-6d8f87b8d06e",
   "metadata": {},
   "source": [
    "# 从零手搓 RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943a164-b997-4947-bce8-8618b421ef3d",
   "metadata": {},
   "source": [
    "## forword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52299c8-f30e-4f86-8f39-c1a35116dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "546887fc-623d-4623-b271-a77b6bf0abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, input_size, hidden_size = 2, 3, 2, 3 # 批次大小、序列长度、输入维度、隐藏层维度\n",
    "num_layers = 1 # rnn层数\n",
    "\n",
    "input = torch.randn(batch_size, seq_len, input_size) # 初始化输入数据\n",
    "h_prev = torch.zeros(batch_size, hidden_size) # 初始化隐藏层状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4beb290-ebac-4347-9a66-40b7360d178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8950,  0.4833, -0.5547],\n",
      "         [ 0.1424,  0.4373, -0.6090],\n",
      "         [-0.5399,  0.7522, -0.0882]],\n",
      "\n",
      "        [[ 0.2022,  0.8119, -0.3363],\n",
      "         [ 0.0075,  0.5236, -0.5589],\n",
      "         [ 0.6017,  0.2810, -0.6089]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([2, 3, 3])\n",
      "tensor([[[-0.5399,  0.7522, -0.0882],\n",
      "         [ 0.6017,  0.2810, -0.6089]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # 初始化rnn\n",
    "rnn_output, h_n = rnn(input, h_prev.unsqueeze(0)) # rnn输出和隐藏层状态\n",
    "print(rnn_output, rnn_output.shape, h_n, h_n.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc017fe9-187a-4981-8f06-1a84680574cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[ 0.5479,  0.4916],\n",
       "                      [-0.2934, -0.2234],\n",
       "                      [-0.2745, -0.0150]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[ 0.1761, -0.3001,  0.5395],\n",
       "                      [-0.2634, -0.2903,  0.3202],\n",
       "                      [-0.4855,  0.2617, -0.0028]])),\n",
       "             ('bias_ih_l0', tensor([ 0.4256,  0.4981, -0.3173])),\n",
       "             ('bias_hh_l0', tensor([ 0.1950,  0.4163, -0.2147]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad63aab-300f-45c0-9d46-bb3e9c58d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN：\n",
    "def __init__(self,input_size=4, hidden_size=3, num_layers=1, batch_first=True):\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "def rnn_forward(input, W_ih, W_hh, b_ih, b_hh, h_prev):\n",
    "    batch_size, seq_len, input_size = input.shape\n",
    "    hidden_size = W_ih.shape[0] # 隐藏层维度, seq_len就等于hidden_size，所以是W_ih.shape[0]\n",
    "    h_output = torch.zeros(batch_size, seq_len, hidden_size) # 初始化一个输出矩阵output 看官方参数来定义\n",
    "    for t in range(seq_len):\n",
    "        x_t = input[:, t, :].unsqueeze(2) # input[:,t,:].shape = [batch_size,input_size] -> (batch_size,input_size,1)\n",
    "\n",
    "        # w_ih_batch.shape = [hidden_size,input_size]->(1,hidden_size,input_size)->(batch_size,hidden_size,input_size)\n",
    "        # tile(batch_size, 1, 1): 第0维变成原来的batch_size倍（默认行复制）其他两维为1保持不动-> (batch_size,hidden_size,input_size)\n",
    "        w_ih_batch = W_ih.unsqueeze(0).tile(batch_size, 1, 1)\n",
    "\n",
    "        # w_hh_batch.shaoe = [hidden_size,input_size]->(1,hidden_size,input_size)->(batch_size,hidden_size,input_size)\n",
    "        w_hh_batch = W_hh.unsqueeze(0).tile(batch_size, 1, 1)\n",
    "\n",
    "        # w_ih_times_x.shape=(batch_size,hidden_size,1) -> (batch_size,hidden_size)\n",
    "        w_ih_times_x = torch.bmm(w_ih_batch, x_t).squeeze(-1)  # W_ih * x_t\n",
    "\n",
    "        # h_prev.unsqueeze(2) : (batch_size,hidden_size,1)\n",
    "        # w_hh_times_h.shape =(batch_size,hidden_size,1)->(batch_size,hidden_size)\n",
    "        w_hh_times_h = torch.bmm(w_hh_batch, h_prev.unsqueeze(2)).squeeze(-1)\n",
    "\n",
    "        # h_prev = (1,batch_size,hidden_size)->(batch_size, hidden_size)\n",
    "        h_prev = torch.tanh(w_ih_times_x + b_ih + w_hh_times_h + b_hh)\n",
    "\n",
    "        h_output[:,t,:] = h_prev\n",
    "        \n",
    "    # 按官方api格式返回\n",
    "    # h_prev.unsqueeze(0) : (1,batch_size,hidden_size) 因为官方参数为(D∗num_layers,bs,hidden_size)\n",
    "    return h_output, h_prev.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70184ead-7f9a-48c7-9307-ac4cfedbf72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom\n",
      "tensor([[[ 0.8950,  0.4833, -0.5547],\n",
      "         [ 0.1424,  0.4373, -0.6090],\n",
      "         [-0.5399,  0.7522, -0.0882]],\n",
      "\n",
      "        [[ 0.2022,  0.8119, -0.3363],\n",
      "         [ 0.0075,  0.5236, -0.5589],\n",
      "         [ 0.6017,  0.2810, -0.6089]]], grad_fn=<TransposeBackward1>)\n",
      "torch.Size([2, 3, 3])\n",
      "tensor([[[-0.5399,  0.7522, -0.0882],\n",
      "         [ 0.6017,  0.2810, -0.6089]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([1, 2, 3])\n",
      "torch api\n",
      "tensor([[[ 0.8950,  0.4833, -0.5547],\n",
      "         [ 0.1424,  0.4373, -0.6090],\n",
      "         [-0.5399,  0.7522, -0.0882]],\n",
      "\n",
      "        [[ 0.2022,  0.8119, -0.3363],\n",
      "         [ 0.0075,  0.5236, -0.5589],\n",
      "         [ 0.6017,  0.2810, -0.6089]]], grad_fn=<CopySlices>)\n",
      "torch.Size([2, 3, 3])\n",
      "tensor([[[-0.5399,  0.7522, -0.0882],\n",
      "         [ 0.6017,  0.2810, -0.6089]]], grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "rnn_output, h_n = rnn(input, h_prev.unsqueeze(0))\n",
    "custom_output, custom_hn = rnn_forward(input, rnn.weight_ih_l0, rnn.weight_hh_l0, rnn.bias_ih_l0, rnn.bias_hh_l0, h_prev)\n",
    "print('custom', rnn_output, rnn_output.shape, h_n, h_n.shape, sep='\\n')\n",
    "print('torch api', custom_output, custom_output.shape, custom_hn, custom_hn.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c5864-7dc1-4c9d-ac3f-91dbfa93aebb",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "### 数据预处理\n",
    "- 读取数据集：\n",
    "  首先需要获取周杰伦的歌词数据集，可以从网络上搜索整理其歌词文本，将所有歌词保存到一个文本文件中，如jaychou_lyrics.txt。使用 Python 的open()函数读取文件内容，并进行必要的字符编码转换 。\n",
    "- 建立字符索引：\n",
    "将歌词中的每个字符映射为一个从 0 开始的连续整数索引，构建字符到索引的字典char_to_idx以及索引到字符的字典idx_to_char。通过遍历歌词文本，找出所有不同的字符，然后为每个字符分配一个唯一的索引。同时，可以得到词典大小vocab_size，即不同字符的数量 。\n",
    "- 数据采样:\n",
    "\n",
    "  对处理后的数据进行采样，以便生成训练所需的小批量数据。常见的采样方式有随机采样和相邻采样两种 ：\n",
    "- 随机采样：\n",
    "  每次从数据中随机选择一定长度的连续字符序列作为一个样本，同时对应的下一个字符作为该样本的标签。例如，若设定时间步数为num_steps，则每次随机选取num_steps个连续字符作为输入样本，其后面的一个字符作为输出标签。\n",
    "相邻采样：按照顺序依次选取连续的字符序列作为样本和标签，即第i个样本的输入是从i到i + num_steps - 1的字符序列，其标签则是从i + 1到i + num_steps的字符序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97bd370-f7ce-40ce-a1b9-81581e393ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda97458-2dfc-465e-86ec-92488878923c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254eb864-0cc4-4bde-9697-0825c8973534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dd3fbe-6bfe-41a1-8f2c-bd332d430b09",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "参数初始化：初始化模型的参数，如词嵌入维度embedding_dim、隐藏层维度hidden_dim等，并定义损失函数和优化器。例如，可以使用交叉熵损失函数nn.CrossEntropyLoss()和随机梯度下降优化器torch.optim.SGD() 。\n",
    "训练循环：在训练循环中，按照设定的批次大小和采样方式获取训练数据，将数据输入到模型中进行前向传播，计算损失值，然后使用优化器进行反向传播更新模型参数。在每个训练周期，可以打印出当前的损失值，以观察模型的训练进度 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1929d48b-43d2-48fb-b9a0-db6967fd8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = None\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_y in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output, hidden = model(batch_x, hidden)\n",
    "            loss = criterion(output, batch_y.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            hidden = hidden.detach()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(data_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec35fc7-096d-4289-ae80-8ffefa1568cf",
   "metadata": {},
   "source": [
    "### 模型测试与效果评估\n",
    "- 生成歌词：训练完成后，可以使用训练好的模型来生成周杰伦风格的歌词。给定一个起始字符或字符序列，通过模型预测下一个可能的字符，然后将预测的字符作为新的输入，继续预测下一个字符，以此类推，生成一段歌词 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ec35fb-0b34-47e5-8bc7-0c3b88eddfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, char_to_idx, idx_to_char, start_text, length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_text = torch.tensor([char_to_idx[char] for char in start_text]).unsqueeze(0)\n",
    "        hidden = None\n",
    "        generated_text = start_text\n",
    "        for _ in range(length):\n",
    "            output, hidden = model(input_text, hidden)\n",
    "            output_probs = torch.softmax(output, dim=1)\n",
    "            top_prob, top_idx = torch.topk(output_probs, k=1)\n",
    "            top_char = idx_to_char[top_idx.item()]\n",
    "            generated_text += top_char\n",
    "            input_text = torch.tensor([top_idx]).unsqueeze(0)\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2de9b-b4b6-4a16-bd29-09dcec41cfa1",
   "metadata": {},
   "source": [
    "- 效果评估：可以从多个角度评估生成歌词的效果，如歌词的通顺性、连贯性、是否符合周杰伦的风格等。一种简单的方法是人工观察和评价生成的歌词，判断其是否具有一定的合理性和艺术感。也可以使用一些自动评估指标，如困惑度（Perplexity）等来定量地评估模型的性能，但困惑度指标并非完全能够准确反映生成文本的质量，仅供参考."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8ca7fb-7be8-44e7-ae72-6d1c7393a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in data_loader:\n",
    "            output, _ = model(batch_x, None)\n",
    "            loss = criterion(output, batch_y.view(-1))\n",
    "            total_loss += loss.item() * batch_y.numel()\n",
    "            total_count += batch_y.numel()\n",
    "    return torch.exp(torch.tensor(total_loss / total_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876c42-584f-46b2-89a6-279b98a06663",
   "metadata": {},
   "source": [
    "通过以上步骤，就可以利用周杰伦的歌词训练 PyTorch RNN 模型，并对生成歌词的效果进行测试和评估 。需要注意的是，由于歌词的生成具有一定的主观性和创造性，模型的表现可能会因多种因素而有所不同，可通过调整模型结构、参数、训练数据等方式来进一步优化模型的性能 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad6d54-1307-44be-8bd5-e7f8f699e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
