{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解码器层\n",
    "\n",
    "\n",
    "解码器层结构如下:\n",
    "\n",
    "![](./images/image-20241103212541411.png)\n",
    "\n",
    "它的组成部分如下:\n",
    "1. embedding层\n",
    "2. GRU 层\n",
    "\n",
    "输入一个批次的文本,先通过Embedding层将其转化为向量。接着送入GRU神经网络, 最后返回当前时间步GRU的输出和隐藏状态\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.GRU = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [batch_size, src_len]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded: [batch_size, src_len, embed_dim]\n",
    "        outputs, hidden = self.GRU(embedded)\n",
    "        # outputs: [batch_size, src_len, hidden_dim]\n",
    "        # hidden: [1, batch_size, hidden_dim]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # query: [batch_size, 1, hidden_dim]\n",
    "        # key: [batch_size, src_len, hidden_dim]\n",
    "        # value: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        # 计算 QK^T\n",
    "        scores = torch.bmm(query, key.transpose(1, 2))\n",
    "        # scores: [batch_size, 1, src_len]\n",
    "\n",
    "        # 缩放\n",
    "        scores = scores / torch.sqrt(\n",
    "            torch.tensor(self.hidden_dim, dtype=torch.float32, device=scores.device)\n",
    "        )\n",
    "        # 应用 softmax\n",
    "        attention_weights = self.softmax(scores)\n",
    "        # attention_weights: [batch_size, 1, src_len]\n",
    "\n",
    "        # 计算上下文向量\n",
    "        context = torch.bmm(attention_weights, value)\n",
    "        # context: [batch_size, 1, hidden_dim]\n",
    "\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        self.GRU = nn.GRU(embed_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input: [batch_size]\n",
    "        # hidden: [1, batch_size, hidden_dim]\n",
    "        # encoder_outputs: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        input = input.unsqueeze(1)\n",
    "        # input: [batch_size, 1]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded: [batch_size, 1, embed_dim]\n",
    "\n",
    "        # 转置 hidden，使其维度与 query 匹配\n",
    "        hidden_transposed = hidden.permute(1, 0, 2)\n",
    "        # hidden_transposed: [batch_size, 1, hidden_dim]\n",
    "\n",
    "        # 计算注意力\n",
    "        context, attention_weights = self.attention(\n",
    "            hidden_transposed, encoder_outputs, encoder_outputs\n",
    "        )\n",
    "        # context: [batch_size, 1, hidden_dim]\n",
    "\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        # rnn_input: [batch_size, 1, embed_dim + hidden_dim]\n",
    "\n",
    "        output, hidden = self.GRU(rnn_input, hidden)\n",
    "        # output: [batch_size, 1, hidden_dim]\n",
    "\n",
    "        output = output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        # output/context: [batch_size, hidden_dim]\n",
    "\n",
    "        prediction = self.fc_out(torch.cat((output, context), dim=1))\n",
    "        # prediction: [batch_size, output_dim]\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, trg_pad_idx, trg_eos_idx):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.trg_pad_idx = trg_pad_idx  # 目标词表中 <pad> 的索引\n",
    "        self.trg_eos_idx = trg_eos_idx  # 目标词表中 <eos> 的索引\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5, max_len=100):\n",
    "        # src: [batch_size, src_len]\n",
    "        # trg: [batch_size, trg_len]\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # 编码器输出和隐藏状态\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        # encoder_outputs: [batch_size, src_len, hidden_dim]\n",
    "        # hidden: [1, batch_size, hidden_dim]\n",
    "\n",
    "        # 解码器的初始输入是 <sos> 标记\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        # 初始化输出张量\n",
    "        outputs = []\n",
    "        outputs.append(torch.zeros(batch_size, trg_vocab_size).to(self.device))\n",
    "\n",
    "        # 用于跟踪每个序列是否已完成\n",
    "        finished = torch.zeros(batch_size, dtype=torch.bool).to(self.device)\n",
    "\n",
    "        for t in range(1, trg.shape[1]):\n",
    "            # 传递当前输入、隐藏状态和编码器输出到解码器\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            # output: [batch_size, output_dim]\n",
    "            # hidden: [1, batch_size, hidden_dim]\n",
    "\n",
    "            # 存储预测结果\n",
    "            outputs.append(output)\n",
    "\n",
    "            # 选择最高概率的词汇作为下一个输入\n",
    "            top1 = output.argmax(1)\n",
    "            # 更新已完成的序列\n",
    "            eos_generated = top1 == self.trg_eos_idx\n",
    "            finished = finished | eos_generated\n",
    "\n",
    "            # 如果所有序列都已完成，提前退出循环\n",
    "            if finished.all():\n",
    "                break\n",
    "\n",
    "            # 决定是否使用教师强制\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "\n",
    "            # 下一个输入\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "            # 对于已完成的序列，后续输入设为 <pad>，避免影响其他序列\n",
    "            input = input.masked_fill(finished, self.trg_pad_idx)\n",
    "\n",
    "        # 将输出列表转换为张量\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        # outputs: [batch_size, seq_len, trg_vocab_size]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 50])\n"
     ]
    }
   ],
   "source": [
    "TRG_PAD_IDX = 0  # <pad> 的索引\n",
    "TRG_EOS_IDX = 1  # <eos> 的索引\n",
    "\n",
    "# 定义模型参数\n",
    "\n",
    "INPUT_DIM = 50  # 源语言词表大小\n",
    "OUTPUT_DIM = 50  # 目标语言词表大小\n",
    "EMBED_DIM = 16  # 词嵌入维度\n",
    "HIDDEN_DIM = 32  # 隐藏状态维度\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化模型\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, EMBED_DIM, HIDDEN_DIM).to(DEVICE)\n",
    "decoder = Decoder(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM).to(DEVICE)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE, TRG_PAD_IDX, TRG_EOS_IDX).to(DEVICE)\n",
    "\n",
    "\n",
    "# 假设有一个批次的数据\n",
    "batch_size = 2\n",
    "src_len = 5\n",
    "trg_len = 7\n",
    "\n",
    "# 随机生成源序列和目标序列\n",
    "src = torch.randint(2, INPUT_DIM, (batch_size, src_len)).to(DEVICE)\n",
    "trg = torch.randint(2, OUTPUT_DIM, (batch_size, trg_len)).to(DEVICE)\n",
    "# 设置第一个时间步为 <sos>\n",
    "trg[:, 0] = 2  # 假设 <sos> 的索引为 2\n",
    "# 手动在目标序列中添加 <eos> 标记\n",
    "trg[:, -1] = TRG_EOS_IDX\n",
    "\n",
    "# 运行模型\n",
    "outputs = model(src, trg)\n",
    "print(outputs.shape)  # 应该为 [batch_size, seq_len, OUTPUT_DIM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
